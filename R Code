first.date <- Sys.Date() - 300
last.date <- Sys.Date()

# To geto sp500
SP500 = GetSP500Stocks()
tickers = SP500[,1] # Pull in tickers
#tickers = sample(tickers, 100) #randomly choose  5sp500 tickers, for testing
tickers = append(tickers, 'ERIC')

# Query data
DATA_query <- BatchGetSymbols(tickers = tickers, 
                              first.date = first.date,
                              last.date = last.date, 
                              cache.folder = file.path(tempdir(), 
                                                       'BGS_Cache') ) # cache in tempdir()

x = nrow(DATA_query[[1]]) # define number of stocks analyzing

# get succesful ticker list from DATA_query[[1]] == 'keep'
S = matrix(data = NA, ncol = 1, nrow = x)
for(i in 1:x){
  if(DATA_query[[1]][i,6] == 'KEEP'){
    S[i] = toString(DATA_query[[1]][i,1])
  }
}
S = S[which(!is.na(S))] # remove NAs
x = length(S)
start_date = matrix(data = NA, ncol = x, nrow = 1)

DATA = list() #aggregate data into lists
for(i in 1:x){
  DATA[[i]] = DATA_query[[2]][which(DATA_query[[2]][,8] == S[i]),c(1:4,7)]
  if(DATA[[i]][nrow(DATA[[i]])-1,5] == DATA[[i]][nrow(DATA[[i]]),5]){
    DATA[[i]] = DATA[[i]][1:(nrow(DATA[[i]])-1),]
    print('Duplicate last date')
  }
  if(any(is.na(DATA[[i]]))){  # NAs = mean of t +/- 1
    na = which(is.na(DATA[[i]]), arr.ind = TRUE) # get NA locations (row, column)
    for(j in 1:nrow(na)){
      DATA[[i]][na[j,1], na[j,2]] = mean(c(DATA[[i]][na[j,1]-1, na[j,2]], DATA[[i]][na[j,1]+1, na[j,2]]))
    }
  }
  start_date[i] = DATA[[i]][1,5]
}
names(DATA) = S # name each df in list
# Unify lenghts -> have all matrices start at most recent start date
for(i in 1:x){
  if(start_date[i] != max(start_date)){
    DATA[[i]] = DATA[[i]][-1,]
  }
}

# Get list of successfule tickers
tickers = names(DATA)


df = DATA[[i]]
etf_name = tickers[i]
# SMA Cross
long = 50
short = 20
sma_long = na.omit(SMA(df$price.close, long))
sma_short = na.omit(SMA(df$price.close, short))
  
  
# MACD
macd = na.omit(MACD(df$price.close, nFast = 12, nSlow = 26, nSig = 9, percent = TRUE))

  
#RSI Bands
rsi = na.omit(RSI(df$price.close, n = 14))
rsi_sd = rollapply(rsi, 20, sd, na.rm = TRUE) # caluclate standard deviation
rsi_mean = rollapply(rsi, 20, mean, na.rm = TRUE) # calc mean for rsi
rsi = rsi[(length(rsi) - length(rsi_sd) + 1):length(rsi)] # shorten rsi to match sd and mean length
rsi_lower = rsi_mean - rsi_sd # calc lower rsi band
rsi_upper = rsi_mean + rsi_sd # calc upper rsi band
rsi = cbind(rsi, rsi_mean, rsi_upper, rsi_lower)
  
# Stochastic RSI
stoch_rsi = na.omit(stoch(rsi[,1], nFastK = 14, nFastD = 3, sSlowD = 3, bounded = TRUE, smooth = 1))

  
# Donchian
donchian = na.omit(DonchianChannel(df[, 2:3], n = 10, include.lag = FALSE))
  
bbands = na.omit(BBands(df[,2:4], n = 20))
  
  
# standardize length of data
new_length = min(length(sma_long),
                 length(sma_short),
                 length(macd[,1]),
                 length(rsi[,1]),
                 length(stoch_rsi[,1]),
                 length(donchian[,1]),
                 length(bbands[,1]))
df = df[(nrow(df) - new_length + 1):nrow(df),]
sma_long = sma_long[(length(sma_long) - new_length + 1):length(sma_long)]
sma_short = sma_short[(length(sma_short) - new_length + 1):length(sma_short)]
macd = macd[(nrow(macd) - new_length + 1):nrow(macd),]
rsi = rsi[(nrow(rsi) - new_length + 1):nrow(rsi),]
stoch_rsi = stoch_rsi[(nrow(stoch_rsi) - new_length + 1):nrow(stoch_rsi),]
donchian = donchian[(nrow(donchian) - new_length + 1):nrow(donchian),]
bbands = bbands[(nrow(bbands) - new_length + 1):nrow(bbands),]
 
